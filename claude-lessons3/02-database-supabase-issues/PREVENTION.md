# Prevention Guide - Stop Database Incidents Before They Start

**Last Updated:** 2025-11-19
**Success Rate:** 0 incidents since implementation (Nov 2025+)

---

## Table of Contents
1. [Pre-Migration Workflow](#pre-migration-workflow)
2. [Migration Creation Best Practices](#migration-creation-best-practices)
3. [RPC Function Validation](#rpc-function-validation)
4. [Post-Migration Sync Script](#post-migration-sync-script)
5. [Deployment Checklist](#deployment-checklist)
6. [Emergency Rollback Procedures](#emergency-rollback-procedures)
7. [CI/CD Integration](#cicd-integration)

---

<a id="pre-migration-workflow"></a>
## Pre-Migration Workflow

### Step 1: Verify Clean State

```bash
#!/bin/bash
# Run before starting any database work

echo "=== Pre-Migration Checks ==="
echo ""

# Check 1: Migration sync status
echo "1. Checking migration sync..."
supabase migration list --linked

# Expected: All local migrations have matching remote timestamp
# BAD:  20251119123456 |                |
# GOOD: 20251119123456 | 20251119123456 | 2025-11-19 12:34:56

echo ""
echo "2. Checking for uncommitted Prisma schema changes..."
git status prisma/schema.prisma

# Expected: "nothing to commit, working tree clean"
# If modified: Someone edited Prisma schema manually (BAD)

echo ""
echo "3. Checking current branch..."
git branch --show-current

# Expected: On a feature branch, not main

echo ""
echo "4. Checking for pending migrations in main..."
git fetch origin main
git log HEAD..origin/main --oneline -- supabase/migrations/

# Expected: No output (you're up to date)
# If output shown: Pull latest migrations first
```

**If any check fails:**
```bash
# Sync migrations first
git pull origin main
supabase db push --linked

# Pull schema updates
npx prisma db pull
./scripts/post-migration-sync.sh

# Now proceed with new migration
```

---

<a id="migration-creation-best-practices"></a>
## Migration Creation Best Practices

### Step 1: Generate Unique Timestamp

```bash
# ALWAYS use 14-digit timestamp
TIMESTAMP=$(date +"%Y%m%d%H%M%S")
echo "Creating migration: $TIMESTAMP"

# Example output: 20251119143022

# NEVER use 8-digit (date-only) timestamp
# BAD: date +"%Y%m%d"  ‚Üí 20251119 (not unique!)
```

### Step 2: Use Migration Template

```bash
# Copy from template
cp supabase/migrations/.template.sql \
   "supabase/migrations/${TIMESTAMP}_add_feature_name.sql"

# Or create from scratch using this structure:
cat > "supabase/migrations/${TIMESTAMP}_add_feature_name.sql" << 'EOF'
-- Migration: [Brief description]
-- Date: YYYY-MM-DD
-- Related: Issue #XXX, ADR-XXX
-- Author: [Your name]

-- ============================================================
-- STEP 1: Table Structure Changes
-- ============================================================

-- Add table (idempotent)
CREATE TABLE IF NOT EXISTS new_table (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  created_at TIMESTAMPTZ DEFAULT now()
);

-- Add column (idempotent)
ALTER TABLE existing_table
ADD COLUMN IF NOT EXISTS new_column TEXT;

-- ============================================================
-- STEP 2: Indexes
-- ============================================================

CREATE INDEX IF NOT EXISTS idx_table_column
ON table_name(column_name);

-- ============================================================
-- STEP 3: Data Backfill (if needed)
-- ============================================================

-- Idempotent update pattern
UPDATE table_name
SET new_column = 'default_value'
WHERE new_column IS NULL;

-- ============================================================
-- STEP 4: RPC Functions (if needed)
-- ============================================================

-- Always use CREATE OR REPLACE (or DROP IF EXISTS first)
CREATE OR REPLACE FUNCTION function_name(...)
RETURNS TABLE (...) AS $$
BEGIN
  -- Function body
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- ============================================================
-- STEP 5: Permissions
-- ============================================================

GRANT SELECT ON new_table TO authenticated;
GRANT EXECUTE ON FUNCTION function_name TO authenticated;

-- ============================================================
-- STEP 6: Comments (Documentation)
-- ============================================================

COMMENT ON TABLE new_table IS
'Description of what this table does.';

COMMENT ON COLUMN table_name.new_column IS
'Description of what this column stores.';

-- ============================================================
-- STEP 7: Notify PostgREST (if using PostgREST)
-- ============================================================

NOTIFY pgrst, 'reload schema';

-- ============================================================
-- STEP 8: Validation Block
-- ============================================================

DO $$
BEGIN
  -- Check table exists
  IF NOT EXISTS (
    SELECT 1 FROM information_schema.tables
    WHERE table_name = 'new_table'
  ) THEN
    RAISE EXCEPTION 'Migration failed: new_table not created';
  END IF;

  -- Check column exists
  IF NOT EXISTS (
    SELECT 1 FROM information_schema.columns
    WHERE table_name = 'existing_table'
    AND column_name = 'new_column'
  ) THEN
    RAISE EXCEPTION 'Migration failed: new_column not created';
  END IF;

  -- Check function exists
  IF NOT EXISTS (
    SELECT 1 FROM pg_proc p
    JOIN pg_namespace n ON p.pronamespace = n.oid
    WHERE n.nspname = 'public'
    AND p.proname = 'function_name'
  ) THEN
    RAISE EXCEPTION 'Migration failed: function_name not created';
  END IF;

  RAISE NOTICE 'Migration successful: [feature description]';
END $$;
EOF
```

### Step 3: Verify Idempotency

**Checklist - Every SQL statement should be idempotent:**

```sql
--  GOOD (idempotent):
CREATE TABLE IF NOT EXISTS ...
ALTER TABLE ... ADD COLUMN IF NOT EXISTS ...
CREATE INDEX IF NOT EXISTS ...
CREATE OR REPLACE FUNCTION ...
INSERT ... ON CONFLICT DO NOTHING
UPDATE ... WHERE condition  -- With WHERE clause limiting scope

--  BAD (not idempotent):
CREATE TABLE ...  -- Fails if table exists
ALTER TABLE ... ADD COLUMN ...  -- Fails if column exists
CREATE INDEX ...  -- Fails if index exists
INSERT ...  -- Fails on duplicate keys
UPDATE ...  -- Updates all rows every time (no WHERE clause)
```

**Test Idempotency:**
```bash
# Run migration twice - should succeed both times
psql "$DATABASE_URL" -f "supabase/migrations/${TIMESTAMP}_migration.sql"
# First run: Creates things

psql "$DATABASE_URL" -f "supabase/migrations/${TIMESTAMP}_migration.sql"
# Second run: Should say "already exists" but not fail
```

---

<a id="rpc-function-validation"></a>
## RPC Function Validation

### The 60% Failure Rate Problem

**Between Oct 19 - Nov 5, 2025:**
- 6 RPC function migrations deployed
- 4 required emergency hotfixes
- 60% failure rate

**Root Cause:** RPC signature drift from table schema

### RPC Validation Checklist

#### Before Creating RPC Function:

```bash
# 1. Get exact table schema
psql "$DATABASE_URL" -c "\d orders"

# Output example:
#                Table "public.orders"
#     Column      |           Type           | Nullable | Default
# ----------------+--------------------------+----------+---------
#  id             | uuid                     | not null | gen_random_uuid()
#  order_number   | text                     | not null |
#  type           | text                     | not null |
#  status         | text                     | not null |
#  version        | integer                  | not null | 1
#  created_at     | timestamp with time zone | not null | now()
#  check_closed_at| timestamp                |          |
```

#### For Each Column in RETURNS TABLE:

```sql
-- Create spreadsheet or checklist:
-- Column Name | Table Type | RPC Type | Match? | Notes
-- order_number | text | text |  |
-- type | text | VARCHAR |  | FIX: Change to text
-- created_at | timestamptz | timestamptz |  |
-- check_closed_at | timestamp | timestamptz |  | FIX: Change to timestamp
```

#### RPC Function Template (Validated):

```sql
-- Get table schema first
-- \d orders

CREATE OR REPLACE FUNCTION create_order_with_audit(
  -- PARAMETERS: Match what calling code sends
  p_restaurant_id UUID,
  p_order_number TEXT,  -- Check: orders.order_number type
  p_type TEXT,          -- Check: orders.type type
  p_status TEXT DEFAULT 'pending'
  -- ... other parameters
)
RETURNS TABLE (
  -- RETURN COLUMNS: EXACTLY match table column types
  id UUID,
  restaurant_id UUID,
  order_number TEXT,          -- Must match orders.order_number (not VARCHAR!)
  type TEXT,                  -- Must match orders.type
  status TEXT,                -- Must match orders.status
  created_at TIMESTAMPTZ,     -- Must match orders.created_at (not TIMESTAMP!)
  check_closed_at TIMESTAMP,  -- Must match orders.check_closed_at (not TIMESTAMPTZ!)
  version INTEGER             -- Must match orders.version
  -- ... ALL other columns from orders table
)
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
  v_order_id UUID;
BEGIN
  -- Insert into table
  INSERT INTO orders (...)
  VALUES (...);

  -- Return ALL columns
  RETURN QUERY
  SELECT
    o.id,
    o.restaurant_id,
    o.order_number,  -- Must be in same order as RETURNS TABLE
    o.type,
    o.status,
    o.created_at,
    o.check_closed_at,
    o.version
    -- ... ALL columns (missing any = production error)
  FROM orders o
  WHERE o.id = v_order_id;

EXCEPTION
  WHEN OTHERS THEN
    RAISE NOTICE 'Function failed: % %', SQLERRM, SQLSTATE;
    RAISE;  -- Re-raise to trigger rollback
END;
$$;

-- CRITICAL: Validate return type matches table
DO $$
DECLARE
  v_function_result TEXT;
BEGIN
  SELECT pg_get_function_result(oid) INTO v_function_result
  FROM pg_proc
  WHERE proname = 'create_order_with_audit'
  ORDER BY oid DESC LIMIT 1;

  -- Check for common mistakes
  IF v_function_result LIKE '%character varying%' THEN
    RAISE EXCEPTION 'ERROR: Function uses VARCHAR, table likely uses TEXT';
  END IF;

  -- Check for missing columns (compare count)
  -- This is a simplified check - expand based on your needs
  IF v_function_result NOT LIKE '%version%' THEN
    RAISE EXCEPTION 'ERROR: Function missing version column';
  END IF;

  RAISE NOTICE 'RPC validation passed';
  RAISE NOTICE 'Function signature: %', v_function_result;
END $$;
```

### RPC Testing Script

```bash
#!/bin/bash
# Test RPC function before deploying

echo "Testing RPC function: create_order_with_audit"
echo ""

# Test 1: Can function be called?
echo "Test 1: Calling function..."
psql "$DATABASE_URL" -c "
SELECT * FROM create_order_with_audit(
  '11111111-1111-1111-1111-111111111111'::UUID,  -- restaurant_id
  'TEST-001',                                      -- order_number
  'online',                                        -- type
  'pending'                                        -- status
);
" > /tmp/rpc_test_output.txt

if [ $? -eq 0 ]; then
  echo " Function executed successfully"
else
  echo "‚úó Function execution failed"
  cat /tmp/rpc_test_output.txt
  exit 1
fi

# Test 2: Check return columns
echo ""
echo "Test 2: Verifying return columns..."
RETURN_COLUMNS=$(psql "$DATABASE_URL" -t -c "
SELECT column_name
FROM information_schema.columns
WHERE table_name = 'orders'
ORDER BY ordinal_position;
")

echo "Table has these columns:"
echo "$RETURN_COLUMNS"

# Test 3: Check for type mismatches
echo ""
echo "Test 3: Checking for common type mismatches..."
psql "$DATABASE_URL" -c "
SELECT
  'Function return type:' AS check,
  pg_get_function_result(oid) AS details
FROM pg_proc
WHERE proname = 'create_order_with_audit';
"

echo ""
echo "If you see 'character varying' above but table uses 'text', FIX IT!"
echo "If you see column count mismatch, FIX IT!"
```

---

<a id="post-migration-sync-script"></a>
## Post-Migration Sync Script

### The Critical Script (Prevents Schema Drift)

**File:** `/Users/mikeyoung/CODING/rebuild-6.0/scripts/post-migration-sync.sh`

**What It Does:**
1. Introspects remote database schema
2. Generates Prisma schema from actual database
3. Fixes known Prisma bugs (@ignore attributes)
4. Shows you what changed

**When to Run:** AFTER EVERY migration deployment

### Usage:

```bash
# After deploying migration
supabase db push --linked

# IMMEDIATELY run post-migration sync
./scripts/post-migration-sync.sh

# Output:
# üîÑ Post-Migration Schema Sync Starting...
#  Loaded environment from .env
#  DATABASE_URL configured
# üì• Introspecting database schema...
#  Schema introspection complete
# üîß Patching @ignore attributes for user_pins relations...
#  Schema patching complete
# üî® Generating TypeScript types...
#  TypeScript types generated
#  Schema changes:
#  prisma/schema.prisma | 15 +++++++++++++++
#  1 file changed, 15 insertions(+)
#  Post-Migration Schema Sync Complete!
```

### Automation (Add to package.json):

```json
{
  "scripts": {
    "db:migrate": "supabase db push --linked && ./scripts/post-migration-sync.sh",
    "db:pull": "npx prisma db pull && ./scripts/post-migration-sync.sh"
  }
}
```

**Now just run:**
```bash
npm run db:migrate  # Deploys migration + syncs schema automatically
```

---

<a id="deployment-checklist"></a>
## Deployment Checklist

### Pre-Deployment (On Your Machine)

```bash
# ‚òê 1. Create migration with 14-digit timestamp
TIMESTAMP=$(date +"%Y%m%d%H%M%S")

# ‚òê 2. Write idempotent SQL
# - All CREATE TABLE IF NOT EXISTS
# - All ADD COLUMN IF NOT EXISTS
# - All INSERT ... ON CONFLICT DO NOTHING
# - Validation block at end

# ‚òê 3. Test migration locally
supabase start  # Start local Supabase
supabase db push  # Test migration on local DB

# ‚òê 4. Run migration twice (test idempotency)
psql "postgresql://postgres:postgres@localhost:54322/postgres" \
  -f "supabase/migrations/${TIMESTAMP}_migration.sql"
# Should succeed both times

# ‚òê 5. If creating/modifying RPC, validate signature
./scripts/validate-rpc-signature.sh create_order_with_audit

# ‚òê 6. Commit migration to git
git add supabase/migrations/${TIMESTAMP}_*.sql
git commit -m "feat(db): [description]"

# ‚òê 7. Push to feature branch
git push origin feature/database-change
```

### Deployment (Production)

```bash
# ‚òê 1. Verify migration sync status
supabase migration list --linked
# Check: No undeployed migrations in local column

# ‚òê 2. Deploy migration to production
supabase db push --linked

# Expected output:
# Applying migration 20251119143022_add_feature.sql...
# NOTICE: Migration successful: [feature description]

# ‚òê 3. CRITICAL: Pull schema back to Prisma
npx prisma db pull

# ‚òê 4. Fix Prisma schema issues
./scripts/post-migration-sync.sh

# ‚òê 5. Verify Prisma schema updated correctly
git diff prisma/schema.prisma
# Should show new model/fields matching migration

# ‚òê 6. Generate TypeScript types
npx prisma generate

# ‚òê 7. Verify migration deployed
supabase migration list --linked
# Check: New migration has timestamp in both Local and Remote columns

# ‚òê 8. Commit Prisma schema changes
git add prisma/schema.prisma
git commit -m "chore(db): update prisma schema after migration"
git push origin main
```

### Post-Deployment Verification (15 Minutes)

```bash
# ‚òê 1. Check production database directly
psql "$DATABASE_URL" -c "\d table_name"
# Verify: New columns exist with correct types

# ‚òê 2. Test RPC functions (if modified)
psql "$DATABASE_URL" -c "SELECT * FROM function_name(...);"
# Verify: Function executes without errors

# ‚òê 3. Monitor production logs
# Render: https://dashboard.render.com ‚Üí [service] ‚Üí Logs
# Vercel: https://vercel.com/[project]/deployments ‚Üí Logs

# Watch for:
# - 42703 (column does not exist)
# - 42804 (type mismatch)
# - 42P01 (relation does not exist)

# ‚òê 4. Run smoke tests
curl -X POST https://api.rebuild6.com/api/v1/orders \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $TOKEN" \
  -d '{
    "restaurant_id": "11111111-1111-1111-1111-111111111111",
    "type": "online",
    "items": [{"id": "..."}]
  }'

# Expected: 200 OK, order created successfully

# ‚òê 5. Check error tracking (if using Sentry/etc)
# Verify: No new database errors in last 15 minutes

# ‚òê 6. Verify WebSocket real-time updates (if applicable)
# Check: Kitchen display updates in real-time
```

---

<a id="emergency-rollback-procedures"></a>
## Emergency Rollback Procedures

### Scenario 1: Migration Causes 500 Errors

**Immediate Response (< 5 minutes):**

```bash
# Step 1: Identify which migration caused the issue
supabase migration list --linked
# Look for most recent migration

# Step 2: Check error logs
# Look for: 42703, 42804, 42P01 error codes

# Step 3: If error is from RPC function type mismatch:
# Quick fix: Deploy hotfix migration with correct types
# (Faster than rollback for RPC issues)

# Step 4: If error is from missing column:
# Option A: Deploy hotfix migration adding column
# Option B: Roll back (see below)
```

**Rollback Decision Matrix:**

| Error Type | Quick Fix | Rollback |
|------------|-----------|----------|
| RPC type mismatch (42804) | Deploy corrected RPC (5 min) | Rollback + redeploy (15 min) |
| Missing column (42703) | Deploy column migration (5 min) | Rollback migration (10 min) |
| Broken RPC logic | Deploy fixed RPC (5 min) | Rollback + test (20 min) |
| Data corruption | **STOP - Incident Commander** | Need data restore |

### Rollback Procedure (Use Only If Quick Fix Not Possible)

```bash
# WARNING: This will undo the migration
# Data added/modified by migration will be lost

# Step 1: Mark migration as reverted
supabase migration repair --status reverted 20251119143022

# Step 2: Manually undo migration changes
psql "$DATABASE_URL" << 'EOF'
BEGIN;

-- Drop added columns (reverse of ALTER TABLE ADD COLUMN)
ALTER TABLE table_name DROP COLUMN IF EXISTS new_column;

-- Drop added functions
DROP FUNCTION IF EXISTS function_name;

-- Drop added tables
DROP TABLE IF EXISTS new_table;

-- If you did data updates, you may need to restore from backup
-- (This is why idempotent migrations are important)

COMMIT;
EOF

# Step 3: Verify rollback
psql "$DATABASE_URL" -c "\d table_name"
# Verify: New column no longer exists

# Step 4: Update Prisma schema
npx prisma db pull
./scripts/post-migration-sync.sh

# Step 5: Monitor production for 15 minutes
# Verify: 500 errors stopped
```

### Data Restore (If Rollback Corrupted Data)

```bash
# This requires Supabase backup feature

# Step 1: Check available backups
# Supabase Dashboard ‚Üí Project ‚Üí Database ‚Üí Backups

# Step 2: Create restore point before restore
# (In case restore makes things worse)

# Step 3: Restore from backup via Dashboard
# Or via CLI (if available):
# supabase db restore --backup-id <backup-id>

# Step 4: Verify data restored
psql "$DATABASE_URL" -c "SELECT COUNT(*) FROM orders;"

# Step 5: Re-deploy migrations (if needed)
supabase db push --linked
```

---

<a id="cicd-integration"></a>
## CI/CD Integration

### GitHub Actions Workflow (Migration Validation)

**File:** `.github/workflows/validate-migrations.yml`

```yaml
name: Validate Database Migrations

on:
  pull_request:
    paths:
      - 'supabase/migrations/**'
      - 'prisma/schema.prisma'
  push:
    branches: [main]
    paths:
      - 'supabase/migrations/**'

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Install Supabase CLI
        run: |
          brew install supabase/tap/supabase

      - name: Check migration timestamps
        run: |
          # Fail if any migration has 8-digit timestamp
          if ls supabase/migrations/*[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]_*.sql 2>/dev/null; then
            echo "ERROR: Migration timestamp must be 14 digits (YYYYMMDDHHmmss)"
            exit 1
          fi
          echo " All migrations have 14-digit timestamps"

      - name: Check idempotency keywords
        run: |
          # Check for idempotent patterns
          for file in supabase/migrations/*.sql; do
            if grep -q "CREATE TABLE" "$file" && ! grep -q "IF NOT EXISTS" "$file"; then
              echo "WARNING: $file may not be idempotent (CREATE TABLE without IF NOT EXISTS)"
            fi
          done

      - name: Verify migration sync
        run: |
          supabase link --project-ref ${{ secrets.SUPABASE_PROJECT_REF }}
          OUTPUT=$(supabase migration list --linked)

          # Check for undeployed local migrations
          if echo "$OUTPUT" | grep -E "^\s+20[0-9]+\s+\|\s+\|"; then
            echo "ERROR: Local migrations not deployed to remote"
            echo "$OUTPUT"
            exit 1
          fi

          echo " Migration histories in sync"

      - name: Check for RPC function changes
        run: |
          # If RPC functions modified, verify types
          CHANGED_FILES=$(git diff --name-only HEAD~1)
          if echo "$CHANGED_FILES" | grep -q "create_order_with_audit"; then
            echo "RPC function modified - manual type validation required"
            echo "Verify: All RETURNS TABLE types match table schema"
          fi

      - name: Comment on PR
        uses: actions/github-script@v6
        with:
          script: |
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: ' Migration validation passed. Remember to run `./scripts/post-migration-sync.sh` after deploying!'
            })
```

### Pre-Commit Hook (Local Validation)

**File:** `.git/hooks/pre-commit` or use `husky`

```bash
#!/bin/bash
# Pre-commit hook to validate migrations

MIGRATIONS=$(git diff --cached --name-only --diff-filter=ACM | grep "supabase/migrations/.*\.sql$")

if [ -n "$MIGRATIONS" ]; then
  echo "Validating database migrations..."

  for file in $MIGRATIONS; do
    # Check 1: 14-digit timestamp
    FILENAME=$(basename "$file")
    if ! [[ $FILENAME =~ ^[0-9]{14}_ ]]; then
      echo "ERROR: $file must have 14-digit timestamp (YYYYMMDDHHmmss)"
      exit 1
    fi

    # Check 2: Has validation block
    if ! grep -q "Migration successful" "$file"; then
      echo "WARNING: $file missing validation block"
    fi

    # Check 3: Idempotent patterns
    if grep -q "CREATE TABLE" "$file" && ! grep -q "IF NOT EXISTS" "$file"; then
      echo "WARNING: $file may not be idempotent (missing IF NOT EXISTS)"
    fi
  done

  echo " Migration validation passed"
fi
```

### Deployment Automation (package.json scripts)

```json
{
  "scripts": {
    "db:migrate": "supabase db push --linked && ./scripts/post-migration-sync.sh",
    "db:migrate:local": "supabase db push && ./scripts/post-migration-sync.sh",
    "db:status": "supabase migration list --linked",
    "db:verify": "./scripts/verify-migration-history.sh",
    "db:test-rpc": "./scripts/test-rpc-functions.sh",
    "db:rollback": "echo 'Use: supabase migration repair --status reverted <timestamp>'",

    "pre-deploy": "npm run db:status && npm run db:verify",
    "deploy:migrations": "npm run db:migrate",
    "post-deploy": "npm run db:verify && npm run db:test-rpc"
  }
}
```

---

## Summary - The Prevention Stack

**Layer 1: Pre-Commit (Local)**
-  Timestamp format validation
-  Idempotency checks
-  Syntax validation

**Layer 2: CI/CD (GitHub Actions)**
-  Migration sync verification
-  RPC function change detection
-  Automated smoke tests

**Layer 3: Pre-Deployment (Manual)**
-  Deployment checklist
-  RPC signature validation
-  Local testing

**Layer 4: Post-Deployment (Automated)**
-  Prisma schema sync (post-migration-sync.sh)
-  Production monitoring
-  Error alerting

**Layer 5: Emergency Response**
-  Rollback procedures
-  Hotfix templates
-  Incident runbooks

**Result:** 0 schema drift incidents since implementation (Nov 2025+)

---

## Related Documentation

- **README.md** - Executive summary
- **INCIDENTS.md** - What happened (learn from failures)
- **PATTERNS.md** - Deep technical patterns
- **QUICK-REFERENCE.md** - Emergency commands

---

**Maintained by:** Engineering Team
**Last Updated:** 2025-11-19
**Effectiveness:** Proven in production (0 incidents post-implementation)
