# Voice Ordering Architecture (WebRTC)
**Last Updated:** 2025-01-18
**Status:** ACTIVE (Production)
**Critical Update:** OpenAI transcription model changed from `whisper-1` to `gpt-4o-transcribe` (Jan 2025)

## Overview
Voice ordering uses OpenAI's Realtime API via direct browser-to-OpenAI WebRTC connections for low-latency, natural voice interactions.

## Architecture Decision
After evaluating three approaches, we selected **Client-Side WebRTC** for production:

| Approach | Latency | Lines of Code | Status |
|----------|---------|---------------|--------|
| Server-Side WebSocket Proxy | 150-250ms | ~1,665 | âŒ Abandoned (Nov 2024) |
| Twilio Phone Integration | 300-400ms | ~1,020 | âŒ Never Deployed |
| **Client WebRTC (ACTIVE)** | **50-100ms** | **~2,500** | **âœ… Production** |

**Why WebRTC Won:**
- **50-70% lower latency** (no server proxy hop)
- **Simpler scaling** (OpenAI handles infrastructure)
- **Native browser support** (no audio encoding complexity)
- **Cost efficient** (no server audio processing)

---

## System Components

### 1. Client-Side (Browser)
```
client/src/modules/voice/
â”œâ”€â”€ components/
â”‚   â””â”€â”€ VoiceControlWebRTC.tsx          # Main UI component
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ WebRTCVoiceClient.ts            # Orchestrator (turn state machine)
â”‚   â”œâ”€â”€ VoiceSessionConfig.ts           # Session config + token management
â”‚   â”œâ”€â”€ WebRTCConnection.ts             # RTCPeerConnection lifecycle
â”‚   â””â”€â”€ VoiceEventHandler.ts            # Realtime API event processing
â””â”€â”€ hooks/
    â””â”€â”€ useWebRTCVoice.ts               # React hook wrapper
```

### 2. Server-Side (Backend)
```
server/src/routes/
â””â”€â”€ realtime.routes.ts                  # POST /api/v1/realtime/session
                                        #   â†’ Fetch ephemeral token
                                        #   â†’ Load menu context
                                        #   â†’ Return session data
```

---

## Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser   â”‚
â”‚  (Kiosk UI) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 1. User clicks "Order by Voice"
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VoiceOrderingMode.tsx         â”‚
â”‚  (Kiosk page wrapper)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ 2. Renders <VoiceControlWebRTC context="kiosk" />
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VoiceControlWebRTC.tsx                        â”‚
â”‚  â€¢ Renders Hold-to-Talk button                â”‚
â”‚  â€¢ Renders transcript/response UI              â”‚
â”‚  â€¢ Calls useWebRTCVoice hook                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ 3. Hook initializes client
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  WebRTCVoiceClient (Orchestrator)              â”‚
â”‚  â€¢ Manages turn state machine                  â”‚
â”‚  â€¢ Delegates to 3 services                     â”‚
â””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚          â”‚              â”‚
  â”‚ 4a       â”‚ 4b           â”‚ 4c
  â–¼          â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Session â”‚ â”‚ WebRTC   â”‚ â”‚ Event        â”‚
â”‚Config  â”‚ â”‚Connectionâ”‚ â”‚ Handler      â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚          â”‚               â”‚
     â”‚ 5. Fetch ephemeral tokenâ”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Backend Server  â”‚
        â”‚ realtime.routes  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ 6. POST /api/v1/realtime/session
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  OpenAI Realtime API     â”‚
        â”‚  (Ephemeral token issuer)â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ 7. Returns:
                 â”‚   â€¢ client_secret.value (ephemeral token)
                 â”‚   â€¢ expires_at (60 seconds)
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Backend Server  â”‚
        â”‚ realtime.routes  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ 8. Adds menu_context (5KB max)
                 â”‚    + restaurant_id
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  VoiceSession    â”‚
        â”‚  Config Service  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ 9. Stores token + menu
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  WebRTC          â”‚
        â”‚  Connection      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ 10. Connects to OpenAI
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  OpenAI Realtime API      â”‚
        â”‚  wss://api.openai.com/v1  â”‚
        â”‚  /realtime?model=gpt-4o-  â”‚
        â”‚  realtime-preview-2025-   â”‚
        â”‚  06-03                    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ 11. WebRTC SDP negotiation
                  â”‚     (RTCPeerConnection)
                  â”‚
                  â”‚ 12. RTCDataChannel ready
                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Event Handler   â”‚
        â”‚  Service         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ 13. Listens for session.created
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  VoiceSession    â”‚
        â”‚  Config Service  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ 14. Builds session config:
                 â”‚   â€¢ instructions (menu + context)
                 â”‚   â€¢ tools (add_to_order, confirm_order, remove_from_order)
                 â”‚   â€¢ voice: "alloy"
                 â”‚   â€¢ turn_detection: server_vad
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Event Handler   â”‚
        â”‚  Service         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ 15. Sends session.update to OpenAI
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  OpenAI Realtime API      â”‚
        â”‚  (Configured with menu +  â”‚
        â”‚   tools)                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ 16. Returns session.updated
                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Event Handler   â”‚
        â”‚  Service         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ 17. Emits 'session.created' event
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  VoiceControl    â”‚
        â”‚  WebRTC.tsx      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ 18. Shows "Ready" UI
                 â”‚
                 â”‚ [USER HOLDS BUTTON]
                 â”‚
                 â”‚ 19. startRecording()
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  WebRTC          â”‚
        â”‚  VoiceClient     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ 20. Turn state: idle â†’ recording
                 â”‚     Enables microphone
                 â”‚     Clears audio buffer
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  WebRTC          â”‚
        â”‚  Connection      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ 21. Streams PCM16 audio chunks
                 â”‚     via RTCDataChannel
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  OpenAI Realtime API      â”‚
        â”‚  (Receives live audio)    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ 22. Sends input_audio_buffer.speech_started
                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Event Handler   â”‚
        â”‚  Service         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ 23. Emits 'speech.started'
                 â”‚
                 â”‚ [USER RELEASES BUTTON]
                 â”‚
                 â”‚ 24. stopRecording()
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  WebRTC          â”‚
        â”‚  VoiceClient     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ 25. Mutes microphone IMMEDIATELY
                 â”‚     Turn state: recording â†’ committing
                 â”‚     Sends input_audio_buffer.commit
                 â”‚     Turn state: committing â†’ waiting_user_final
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  OpenAI Realtime API      â”‚
        â”‚  (Processes committed     â”‚
        â”‚   audio)                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ 26. Sends conversation.item.input_audio_transcription.completed
                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Event Handler   â”‚
        â”‚  Service         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ 27. Emits 'transcript' event
                 â”‚     Turn state: waiting_user_final â†’ waiting_response
                 â”‚
                 â”‚ 28. Sends response.create (triggers AI response)
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  OpenAI Realtime API      â”‚
        â”‚  (Generates response)     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ 29. May call function (add_to_order)
                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Event Handler   â”‚
        â”‚  Service         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ 30. Executes function locally:
                 â”‚   â€¢ Fuzzy menu matching
                 â”‚   â€¢ Adds items to cart
                 â”‚   â€¢ Returns result to OpenAI
                 â”‚
                 â”‚ 31. Sends response.function_call_arguments.done
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  OpenAI Realtime API      â”‚
        â”‚  (Continues response with â”‚
        â”‚   function result)        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ 32. Sends response.audio.delta chunks
                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Event Handler   â”‚
        â”‚  Service         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ 33. Emits 'response.text' (for UI)
                 â”‚     Plays audio via <audio> element
                 â”‚
                 â”‚ 34. Sends response.audio.done
                 â”‚     Turn state: waiting_response â†’ idle
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  VoiceControl    â”‚
        â”‚  WebRTC.tsx      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ 35. Updates UI:
                 â”‚   â€¢ Shows transcript
                 â”‚   â€¢ Shows AI response text
                 â”‚   â€¢ Updates cart visually
                 â”‚
                 â”‚ [REPEAT: User holds button again]
```

---

## Critical Configuration: Context Prop

**THE FIX THAT SOLVED MENU KNOWLEDGE:**

```tsx
// âŒ WRONG (defaults to 'kiosk' but doesn't pass prop)
<VoiceControlWebRTC
  onTranscript={handleTranscript}
  onOrderDetected={handleOrder}
/>

// âœ… CORRECT (explicit context prop)
<VoiceControlWebRTC
  context="kiosk"  // <-- CRITICAL!
  onTranscript={handleTranscript}
  onOrderDetected={handleOrder}
/>
```

**Why this matters:**
- `VoiceSessionConfig.ts` builds different instructions based on context
- `context="kiosk"` â†’ Full menu + function tools
- `context="server"` â†’ No menu, different instructions
- **Missing prop** â†’ Defaults to `undefined` â†’ wrong config sent to OpenAI

---

## Turn State Machine

```
â”Œâ”€â”€â”€â”€â”€â”  startRecording()   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚IDLE â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ RECORDING â”‚
â””â”€â”€â–²â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
   â”‚                              â”‚
   â”‚                              â”‚ stopRecording()
   â”‚                              â–¼
   â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚                        â”‚ COMMITTING â”‚ (brief, ~10ms)
   â”‚                        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
   â”‚                              â”‚
   â”‚                              â”‚ auto-transition
   â”‚                              â–¼
   â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚                     â”‚WAITING_USER_FINAL â”‚ (waiting for transcript)
   â”‚                     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚                           â”‚
   â”‚                           â”‚ transcript received
   â”‚                           â–¼
   â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚                     â”‚ WAITING_RESPONSE  â”‚ (AI thinking/speaking)
   â”‚                     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚                           â”‚
   â”‚                           â”‚ response.audio.done
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**State Guards:**
- `startRecording()` only allowed from `idle`
- `stopRecording()` only allowed from `recording`
- **Debouncing:** Minimum 250ms between commits

---

## Menu Context Injection

**Backend (`realtime.routes.ts:25-132`):**
1. Fetch menu items from database
2. Fetch categories to map IDs â†’ names
3. Format menu with human-readable categories
4. **CRITICAL:** Limit to 5KB to prevent OpenAI rejection
5. Include in session data: `menu_context`

**Frontend (`VoiceSessionConfig.ts:95-149`):**
1. Receive `menu_context` from backend
2. Build instructions: `KIOSK_INSTRUCTIONS + menu_context`
3. Build tools: `add_to_order`, `confirm_order`, `remove_from_order`
4. Send `session.update` with full config

---

## Function Calling

### Available Functions

#### 1. `add_to_order`
```json
{
  "name": "add_to_order",
  "description": "Add items to the customer's order",
  "parameters": {
    "type": "object",
    "properties": {
      "items": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "name": "string",
            "quantity": "number",
            "modifications": "array<string>",
            "special_instructions": "string"
          }
        }
      }
    },
    "required": ["items"]
  }
}
```

#### 2. `confirm_order`
```json
{
  "name": "confirm_order",
  "description": "Confirm the complete order for checkout",
  "parameters": {
    "type": "object",
    "properties": {
      "order_type": {
        "type": "string",
        "enum": ["dine_in", "to_go"]
      }
    },
    "required": ["order_type"]
  }
}
```

#### 3. `remove_from_order`
```json
{
  "name": "remove_from_order",
  "description": "Remove specific items from the order",
  "parameters": {
    "type": "object",
    "properties": {
      "item_name": "string"
    },
    "required": ["item_name"]
  }
}
```

### Function Execution Flow

1. **OpenAI calls function** â†’ `response.function_call_arguments.delta`
2. **Event handler receives** â†’ `VoiceEventHandler:269-331`
3. **Execute handler:**
   - `add_to_order` â†’ Fuzzy menu matching â†’ Add to cart
   - `confirm_order` â†’ Set order type â†’ Trigger checkout
   - `remove_from_order` â†’ Find item â†’ Remove from cart
4. **Return result** â†’ `conversation.item.create` (function_call_output)
5. **Continue response** â†’ `response.create`

---

## Fuzzy Menu Matching

**Problem:** User says "greek salad" but menu has "The Greek Salad"

**Solution:** Multi-strategy fuzzy matching (`VoiceOrderingMode.tsx:175-230`)

```typescript
const menuItem = menuItems.find(m => {
  const itemNameLower = item.name.toLowerCase();
  const menuNameLower = m.name.toLowerCase();

  // 1. Exact match
  if (menuNameLower === itemNameLower) return true;

  // 2. Contains match
  if (menuNameLower.includes(itemNameLower) ||
      itemNameLower.includes(menuNameLower)) return true;

  // 3. Known variations
  const variations: Record<string, string[]> = {
    'soul bowl': ['soul', 'bowl', 'sobo', 'solo bowl'],
    'greek salad': ['greek', 'greek salad'],
    'peanut noodles': ['peanut', 'noodles', 'peanut noodle']
  };

  for (const [menuKey, aliases] of Object.entries(variations)) {
    if (menuNameLower.includes(menuKey) &&
        aliases.some(alias => itemNameLower.includes(alias))) {
      return true;
    }
  }

  return false;
});
```

---

## Error Handling

### 1. Connection Failures
```typescript
// WebRTCConnection emits 'error' event
this.connection.on('error', (error: Error) => {
  this.emit('error', error);
  // UI shows: "Connection lost. Please try again."
});
```

### 2. Session Expiration
```typescript
// Token expires after 60 seconds
this.eventHandler.on('session_expired', async () => {
  await this.handleSessionExpired(); // Fetch new token + reconnect
});
```

### 3. Rate Limits
```typescript
// OpenAI rate limit exceeded
this.eventHandler.on('rate_limit_error', () => {
  // UI shows: "Service busy. Please wait a moment."
});
```

### 4. Transcript Timeout
```typescript
// No transcript received within 10 seconds
this.turnStateTimeout = setTimeout(() => {
  if (this.turnState === 'waiting_user_final') {
    this.resetTurnState(); // Back to idle
  }
}, 10000);
```

---

## Performance Optimizations

### 1. Lazy Loading
```tsx
// VoiceOrderingMode.tsx
const VoiceControlWebRTC = lazy(() =>
  import('@/modules/voice/components/VoiceControlWebRTC')
    .then(m => ({ default: m.VoiceControlWebRTC }))
);
```

### 2. Audio Buffer Management
```typescript
// Clear buffer before recording starts
this.eventHandler.sendEvent({
  type: 'input_audio_buffer.clear'
});
```

### 3. Immediate Mic Mute
```typescript
// stopRecording() mutes BEFORE sending commit
this.connection.disableMicrophone(); // <-- FIRST
this.eventHandler.sendEvent({
  type: 'input_audio_buffer.commit'
});
```

### 4. Menu Context Size Limit
```typescript
// Backend limits menu to 5KB
const MAX_MENU_CONTEXT_LENGTH = 5000;
if (menuContext.length > MAX_MENU_CONTEXT_LENGTH) {
  menuContext = menuContext.substring(0, MAX_MENU_CONTEXT_LENGTH) +
    '\n\n[Menu truncated - complete menu available on screen]';
}
```

---

## Testing

### Manual Testing Checklist
- [ ] Hold button â†’ Mic enables
- [ ] Release button â†’ Mic mutes immediately
- [ ] Transcript appears within 2 seconds
- [ ] AI response plays with audio
- [ ] Function calls add items to cart
- [ ] Cart updates visually
- [ ] Checkout confirmation works
- [ ] Error states show helpful messages

### Common Issues
1. **"Agent has no menu knowledge"**
   - âœ… **Fixed:** Add `context="kiosk"` prop to VoiceControlWebRTC

2. **"Race condition: session.update sent before session.created"**
   - âœ… **Fixed:** Event handler waits for session.created before sending config

3. **"Menu context too large (>50KB)"**
   - âœ… **Fixed:** Backend truncates to 5KB before sending

---

## Future Enhancements

### 1. Barge-in Support
Currently missing from WebRTC implementation. User cannot interrupt AI response.

**Plan:** Port from abandoned `EnhancedOpenAIAdapter.ts:232-257`:
```typescript
// Detect user speech during AI response
if (this.isSpeaking && userSpeechDetected) {
  this.sendToOpenAI({ type: 'response.cancel' });
  this.clearAudioBuffers();
}
```

### 2. Phone Integration (Post-MVP)
Reuse salvaged code from `docs/archive/2025-01/VOICE_CODE_SALVAGE.md`:
- G.711 Î¼-law audio conversion
- Twilio Media Streams integration
- Debug dashboard for monitoring

### 3. Debug Dashboard
Adapt salvaged dashboard for WebRTC monitoring:
- Real-time session tracking
- Transcript logging
- Function call inspection
- Audio buffer visualization

---

## Related Documentation
- [Salvaged Voice Code](../../archive/2025-01/VOICE_CODE_SALVAGE.md)
- [OpenAI Realtime API](../../reference/api/openai-realtime/README.md)
- [Voice Ordering How-To](../VOICE_ORDERING_WEBRTC.md)

---

## Troubleshooting

### Agent doesn't know the menu
**Symptom:** AI says "I don't have access to the menu"
**Cause:** Missing `context="kiosk"` prop
**Fix:** Add prop to VoiceControlWebRTC component

### Transcript never appears (CRITICAL - Jan 2025 Issue)
**Symptom:** Recording indicator shows, audio transmits, but no transcript text appears
**Causes:**
1. **Using deprecated `whisper-1` model** (Most Common - Fixed Jan 2025)
   - OpenAI deprecated `whisper-1` for Realtime API in early 2025
   - Fix: Update to `gpt-4o-transcribe` model in VoiceSessionConfig.ts
   - See: `docs/archive/2025-01/VOICE_FIX_TRANSCRIPTION_MODEL_2025-01-18.md`
2. Audio buffer not committed or token expired
3. Network interruption during transmission

**Diagnostic Steps:**
1. Check browser console for transcription events:
   - `conversation.item.input_audio_transcription.delta` (should appear during speech)
   - `conversation.item.input_audio_transcription.completed` (should appear after speech ends)
2. If NO transcription events appear:
   - Verify model is `gpt-4o-transcribe` (NOT `whisper-1`)
   - Check console for `session.update` logs showing correct model
3. Check for `input_audio_buffer.commit` events
4. Verify token hasn't expired (check timestamp)

**Expected Console Output (After Fix):**
```
ğŸ“¤ [WebRTCVoiceClient] Sending session.update:
  model: "gpt-4o-transcribe"

ğŸ“ [VoiceEventHandler] Got transcript delta: "I'd like"
ğŸ“ [VoiceEventHandler] Got transcript delta: " a greek"
ğŸ“ [VoiceEventHandler] Got transcript delta: " salad"
âœ… [VoiceEventHandler] Got transcript completed: "I'd like a greek salad"
```

### Cart doesn't update
**Symptom:** AI confirms order but cart unchanged
**Cause:** Function call failing or fuzzy matching not finding item
**Fix:** Check browser console for `order.items.added` events

### "Session expired" error
**Symptom:** Connection works for ~60s then fails
**Cause:** Ephemeral token expired (60s lifespan)
**Fix:** Normal - client auto-reconnects with new token

---

## OpenAI API Breaking Change (January 2025)

**CRITICAL:** On approximately January 2025, OpenAI silently deprecated the `whisper-1` model for Realtime API transcription, causing complete voice ordering failure.

**Symptoms:**
- âœ… Session connects successfully
- âœ… Audio transmits (49KB+ sent)
- âœ… Agent responds with voice
- âŒ NO transcription events received
- âŒ State machine stuck in `waiting_user_final` (10s timeout)
- âŒ Orders cannot be processed

**Root Cause:**
OpenAI deprecated `whisper-1` without advance notice. The configuration was accepted without error, but transcription was silently ignored.

**Fix (Applied Jan 18, 2025):**
```typescript
// BEFORE (Broken)
input_audio_transcription: {
  model: 'whisper-1',
  language: 'en'
}

// AFTER (Fixed)
input_audio_transcription: {
  model: 'gpt-4o-transcribe'  // Auto-detects language
}
```

**Files Updated:**
- `client/src/modules/voice/services/VoiceSessionConfig.ts:252-254`
- Commit: `3a5d126f`

**References:**
- Detailed RCA: `docs/archive/2025-01/VOICE_FIX_TRANSCRIPTION_MODEL_2025-01-18.md`
- OpenAI Community: https://community.openai.com/t/cant-get-the-user-transcription-in-realtime-api/1076308

**Monitoring Recommendations:**
1. Add alerts for missing transcription events
2. Monitor OpenAI community forums for API changes
3. Log all transcription event timestamps for analysis
4. Test transcription after any OpenAI API updates

---

**Maintainers:** @mikeyoung
**Last Reviewed:** 2025-01-18
